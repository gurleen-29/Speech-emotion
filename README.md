Speech Emotion Recognition is a very interesting yet very challenging task of human computer interaction. Speech Emotion Recognition is the process of trying to identify affective and emotional states in speech. This makes use of the fact that tone and pitch in the voice frequently convey underlying emotion. In order to grasp human emotion, animals like dogs and horses also use this phenomenon. In this project, I tried to recognize emotion in short voice message. I have used four datasets (SAVEE, RAVDESS, TESS, and CREMA-D) in this project which contains 6 types of main emotions: Happy, Fear, Angry, Disgust, Sad or Neutral. In previous studies, we have seen that everyone has worked on separate datasets but in my project, we have combined the four datasets (SAVEE, RAVDESS, TESS, CREMA-D) into a single file and then we send input wav file as our input to the model. Then we had performed feature extraction techniques (MFCC) for reducing noise from the data and then organized the sequential data obtained in the 3D array form that the CNN model accepts. Using the Matplotlib library, we  put the data into a graphical form, then after some repeated testing with various values reveals that the model's average accuracy is 70% at testing and 95% at the training phase.
