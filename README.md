Speech Emotion Recognition is an interesting yet challenging task of human computer interaction. Speech Emotion Recognition is the process of trying to identify affective and emotional states in speech. This makes use of the fact that tone and pitch in the voice frequently convey underlying emotion. In order to grasp human emotion, animals like dogs and horses also use this phenomenon. In this project, I tried to recognize emotion in short voice message. I have used four datasets (SAVEE, RAVDESS, TESS, and CREMA-D) in this project which contains 6 types of main emotions: Happy, Fear, Angry, Disgust, Sad or Neutral. In previous studies, we have seen that everyone has worked on separate datasets but in my project, I have combined the four datasets (SAVEE, RAVDESS, TESS, CREMA-D) into a single file and then I send input wav file as input to the model. Then I had performed feature extraction techniques (MFCC) for reducing noise from the data and then organized the sequential data obtained in the 3D array form that the CNN model accepts. 
